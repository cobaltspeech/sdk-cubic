<!DOCTYPE html>
<html>
  <head>
    <title>Cubic SDK -- Cobalt</title>
    
      <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<title>Proto Generated Docs :: Cubic SDK -- Cobalt</title>
<link rel="shortcut icon" href="/sdk-cubic/images/favicon.ico" type="image/x-icon" />
<link href="/sdk-cubic/css/nucleus.css" rel="stylesheet">
<link href="/sdk-cubic/css/font-awesome.min.css" rel="stylesheet">
<link href="/sdk-cubic/css/hybrid.css" rel="stylesheet">
<link href="/sdk-cubic/css/featherlight.min.css" rel="stylesheet">
<link href="/sdk-cubic/css/auto-complete.css" rel="stylesheet">
<link href="/sdk-cubic/theme-original/style.css" rel="stylesheet">

  <link href="/sdk-cubic/theme-original/variant-blue.css" rel="stylesheet">

<link rel="stylesheet" href="/sdk-cubic/css/bootstrap.min.css">
<script src="/sdk-cubic/js/jquery-2.x.min.js"></script>
<style type="text/css">
  :root #header + #content > #left > #rlblock_left {
    display:none !important;
  }
</style>
<link href="/sdk-cubic/css/tabs.css" rel="stylesheet" type="text/css">
<script src="/sdk-cubic/js/tabs.js"></script>


    
  </head>
  <body data-url="/sdk-cubic/protobuf/autogen-doc-cubic-proto/">
    
      <div id="headermain"></div>
<nav id="sidebar" class="showVisitedLinks">



<div class="highlightable">
  <div id="header-wrapper">
    <div id="header">
      
	
  
    <p><img src="/sdk-cubic/images/logo-white.png" alt="Cobalt's SDK Documentation" /></p>

<p>Cubic SDK &ndash; Cobalt</p>

  


    </div>
        <div class="searchbox">
		    <label for="search-by"><i class="fa fa-search"></i></label>
		    <input data-search-input id="search-by" type="text" placeholder="Search...">
		    <span data-search-clear=""><i class="fa fa-close"></i></span>
		</div>
		<script type="text/javascript" src="/sdk-cubic/js/lunr.min.js"></script>
		<script type="text/javascript" src="/sdk-cubic/js/auto-complete.js"></script>
		<script type="text/javascript">
        
            var baseurl = "https:\/\/cobaltspeech.github.io\/sdk-cubic";
        
		</script>
		<script type="text/javascript" src="/sdk-cubic/js/search.js"></script>
  </div>

      <ul class="topics">
            <li data-nav-id="/sdk-cubic/" class="dd-item">
            <a href="/sdk-cubic/"><i class="fa fa-fw fa-home"></i></a>
            </li>
    <li data-nav-id="/sdk-cubic/getting-started/" class="dd-item alwaysopen haschildren
        ">
      <div>
      <a href="/sdk-cubic/getting-started/">Getting started</a>
            <i class="fa fa-angle-down fa-lg category-icon"></i><i class="fa fa-circle-thin read-icon"></i>
      </div>
        <ul>
      <li data-nav-id="/sdk-cubic/getting-started/installation/" class="dd-item">
        <div>
          <a href="/sdk-cubic/getting-started/installation/">
            Installation
          </a><i class="fa fa-circle-thin read-icon"></i>
        </div>
    </li>
      <li data-nav-id="/sdk-cubic/getting-started/connecting/" class="dd-item">
        <div>
          <a href="/sdk-cubic/getting-started/connecting/">
            Setup Connection
          </a><i class="fa fa-circle-thin read-icon"></i>
        </div>
    </li>
      <li data-nav-id="/sdk-cubic/getting-started/recognize/" class="dd-item">
        <div>
          <a href="/sdk-cubic/getting-started/recognize/">
            Synchronous Recognition
          </a><i class="fa fa-circle-thin read-icon"></i>
        </div>
    </li>
      <li data-nav-id="/sdk-cubic/getting-started/streaming/" class="dd-item">
        <div>
          <a href="/sdk-cubic/getting-started/streaming/">
            Streaming Recognition
          </a><i class="fa fa-circle-thin read-icon"></i>
        </div>
    </li>
        </ul>
    </li>
    <li data-nav-id="/sdk-cubic/protobuf/" class="dd-item parent haschildren
        ">
      <div>
      <a href="/sdk-cubic/protobuf/">Protobuf Reference</a>
            <i class="fa fa-angle-down fa-lg category-icon"></i><i class="fa fa-circle-thin read-icon"></i>
      </div>
        <ul>
      <li data-nav-id="/sdk-cubic/protobuf/autogen-doc-cubic-proto/" class="dd-item active">
        <div>
          <a href="/sdk-cubic/protobuf/autogen-doc-cubic-proto/">
            Proto Generated Docs
          </a><i class="fa fa-circle-thin read-icon"></i>
        </div>
    </li>
        </ul>
    </li>



        <section id="shortcuts">
                <li class="" role=""><h3>More</h3><a href="https://github.com/cobaltspeech/sdk-cubic" target="_blank" rel="noopener"><i class='fa fa-github'></i> <label>Github repo</label></a></li>
                <li class="" role=""><a href="https://www.cobaltspeech.com/contact" target="_blank" rel="noopener"><i class='fa fa-bookmark'></i> <label>Contact us</label></a></li>
        </section>
            <a id="clear-history" class="" href="#" data-clear-history-toggle=""><i class="fa  fa-history"></i> Clear History</a>

    <hr />
    <li></li>
    
    </ul>

 <section id="footer">
    </section>
  </div>
</nav>



<section id="body">
<div id="overlay"></div>
<div class="padding highlightable">

  <div id="top-bar">
    <div id="breadcrumbs" itemscope="" itemtype="http://data-vocabulary.org/Breadcrumb">
        <span id="sidebar-toggle-span">
          <a href="#" id="sidebar-toggle" data-sidebar-toggle="">
            <i class="fa fa-bars"></i>
          </a>
        </span>
        <span id="toc-menu"><i class="fa fa-list-alt"></i></span>
        <span class="links">
        







 <a href='/sdk-cubic/'>Cubic SDK Documentation</a> > <a href='/sdk-cubic/protobuf/'>Protobuf Reference</a> > Proto Generated Docs

 

 

   
        </span>
    </div>
    
    
    <div class="progress">
        <div class="wrapper">
    <nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#cubic-proto">cubic.proto</a>
<ul>
<li><a href="#service-cubic">Service: Cubic</a></li>
<li><a href="#message-confusionnetworkarc">Message: ConfusionNetworkArc</a></li>
<li><a href="#message-confusionnetworklink">Message: ConfusionNetworkLink</a></li>
<li><a href="#message-listmodelsrequest">Message: ListModelsRequest</a></li>
<li><a href="#message-listmodelsresponse">Message: ListModelsResponse</a></li>
<li><a href="#message-model">Message: Model</a></li>
<li><a href="#message-modelattributes">Message: ModelAttributes</a></li>
<li><a href="#message-recognitionalternative">Message: RecognitionAlternative</a></li>
<li><a href="#message-recognitionaudio">Message: RecognitionAudio</a></li>
<li><a href="#message-recognitionconfig">Message: RecognitionConfig</a></li>
<li><a href="#message-recognitionconfusionnetwork">Message: RecognitionConfusionNetwork</a></li>
<li><a href="#message-recognitionresponse">Message: RecognitionResponse</a></li>
<li><a href="#message-recognitionresult">Message: RecognitionResult</a></li>
<li><a href="#message-recognizerequest">Message: RecognizeRequest</a></li>
<li><a href="#message-streamingrecognizerequest">Message: StreamingRecognizeRequest</a></li>
<li><a href="#message-versionresponse">Message: VersionResponse</a></li>
<li><a href="#message-wordinfo">Message: WordInfo</a></li>
<li><a href="#enum-recognitionconfig-encoding">Enum: RecognitionConfig.Encoding</a></li>
</ul></li>
<li><a href="#scalar-value-types">Scalar Value Types</a></li>
</ul></li>
</ul>
</nav>
        </div>
    </div>
    

  </div>


<div id="body-inner">
  
    <h1>Proto Generated Docs</h1>
  



    
    
    
    

<h2 id="cubic-proto">cubic.proto</h2>

<h3 id="service-cubic">Service: Cubic</h3>

<p>Service that implements the Cobalt Cubic Speech Recognition API</p>

<table>
<thead>
<tr>
<th>Method Name</th>
<th>Request Type</th>
<th>Response Type</th>
<th>Description</th>
</tr>
</thead>

<tbody>
<tr>
<td>Version</td>
<td>.google.protobuf.Empty</td>
<td>VersionResponse</td>
<td>Queries the Version of the Server</td>
</tr>

<tr>
<td>ListModels</td>
<td>ListModelsRequest</td>
<td>ListModelsResponse</td>
<td>Retrieves a list of available speech recognition models</td>
</tr>

<tr>
<td>Recognize</td>
<td>RecognizeRequest</td>
<td>RecognitionResponse</td>
<td>Performs synchronous speech recognition: receive results after all audio has been sent and processed. It is expected that this request be typically used for short audio content: less than a minute long. For longer content, the <code>StreamingRecognize</code> method should be preferred.</td>
</tr>

<tr>
<td>StreamingRecognize</td>
<td>StreamingRecognizeRequest</td>
<td>RecognitionResponse</td>
<td>Performs bidirectional streaming speech recognition. Receive results while sending audio. This method is only available via GRPC and not via HTTP+JSON. However, a web browser may use websockets to use this service.</td>
</tr>
</tbody>
</table>

<p><!-- end services --></p>

<h3 id="message-confusionnetworkarc">Message: ConfusionNetworkArc</h3>

<p>An Arc inside a Confusion Network Link</p>

<table>
<thead>
<tr>
<th>Field</th>
<th>Type</th>
<th>Label</th>
<th>Description</th>
</tr>
</thead>

<tbody>
<tr>
<td>word</td>
<td>string</td>
<td></td>
<td><p>Word in the recognized transcript</p></td>
</tr>

<tr>
<td>confidence</td>
<td>double</td>
<td></td>
<td><p>Confidence estimate between 0 and 1. A higher number represents a higher likelihood that the word was correctly recognized.</p></td>
</tr>
</tbody>
</table>

<h3 id="message-confusionnetworklink">Message: ConfusionNetworkLink</h3>

<p>A Link inside a confusion network</p>

<table>
<thead>
<tr>
<th>Field</th>
<th>Type</th>
<th>Label</th>
<th>Description</th>
</tr>
</thead>

<tbody>
<tr>
<td>start_time</td>
<td>google.protobuf.Duration</td>
<td></td>
<td><p>Time offset relative to the beginning of audio received by the recognizer and corresponding to the start of this link</p></td>
</tr>

<tr>
<td>duration</td>
<td>google.protobuf.Duration</td>
<td></td>
<td><p>Duration of the current link in the confusion network</p></td>
</tr>

<tr>
<td>arcs</td>
<td>ConfusionNetworkArc</td>
<td>repeated</td>
<td><p>Arcs between this link</p></td>
</tr>
</tbody>
</table>

<h3 id="message-listmodelsrequest">Message: ListModelsRequest</h3>

<p>The top-level message sent by the client for the <code>ListModels</code> method.</p>

<p>This message is empty and has no fields.</p>

<h3 id="message-listmodelsresponse">Message: ListModelsResponse</h3>

<p>The message returned to the client by the <code>ListModels</code> method.</p>

<table>
<thead>
<tr>
<th>Field</th>
<th>Type</th>
<th>Label</th>
<th>Description</th>
</tr>
</thead>

<tbody>
<tr>
<td>models</td>
<td>Model</td>
<td>repeated</td>
<td><p>List of models available for use that match the request.</p></td>
</tr>
</tbody>
</table>

<h3 id="message-model">Message: Model</h3>

<p>Description of a Cubic Model</p>

<table>
<thead>
<tr>
<th>Field</th>
<th>Type</th>
<th>Label</th>
<th>Description</th>
</tr>
</thead>

<tbody>
<tr>
<td>id</td>
<td>string</td>
<td></td>
<td><p>Unique identifier of the model. This identifier is used to choose the model that should be used for recognition, and is specified in the <code>RecognitionConfig</code> message.</p></td>
</tr>

<tr>
<td>name</td>
<td>string</td>
<td></td>
<td><p>Model name. This is a concise name describing the model, and maybe presented to the end-user, for example, to help choose which model to use for their recognition task.</p></td>
</tr>

<tr>
<td>attributes</td>
<td>ModelAttributes</td>
<td></td>
<td><p>Model attributes</p></td>
</tr>
</tbody>
</table>

<h3 id="message-modelattributes">Message: ModelAttributes</h3>

<p>Attributes of a Cubic Model</p>

<table>
<thead>
<tr>
<th>Field</th>
<th>Type</th>
<th>Label</th>
<th>Description</th>
</tr>
</thead>

<tbody>
<tr>
<td>sample_rate</td>
<td>uint32</td>
<td></td>
<td><p>Audio sample rate supported by the model</p></td>
</tr>
</tbody>
</table>

<h3 id="message-recognitionalternative">Message: RecognitionAlternative</h3>

<p>A recognition hypothesis</p>

<table>
<thead>
<tr>
<th>Field</th>
<th>Type</th>
<th>Label</th>
<th>Description</th>
</tr>
</thead>

<tbody>
<tr>
<td>transcript</td>
<td>string</td>
<td></td>
<td><p>Text representing the transcription of the words that the user spoke.</p></td>
</tr>

<tr>
<td>confidence</td>
<td>double</td>
<td></td>
<td><p>Confidence estimate between 0 and 1. A higher number represents a higher likelihood of the output being correct.</p></td>
</tr>

<tr>
<td>words</td>
<td>WordInfo</td>
<td>repeated</td>
<td><p>A list of word-specific information for each recognized word. This is available only if <code>enable_word_confidence</code> or <code>enable_word_time_offsets</code> was set to <code>true</code> in the <code>RecognitionConfig</code>.</p></td>
</tr>

<tr>
<td>start_time</td>
<td>google.protobuf.Duration</td>
<td></td>
<td><p>Time offset relative to the beginning of audio received by the recognizer and corresponding to the start of this utterance.</p></td>
</tr>

<tr>
<td>duration</td>
<td>google.protobuf.Duration</td>
<td></td>
<td><p>Duration of the current utterance in the spoken audio.</p></td>
</tr>
</tbody>
</table>

<h3 id="message-recognitionaudio">Message: RecognitionAudio</h3>

<p>Audio to be sent to the recognizer</p>

<table>
<thead>
<tr>
<th>Field</th>
<th>Type</th>
<th>Label</th>
<th>Description</th>
</tr>
</thead>

<tbody>
<tr>
<td>data</td>
<td>bytes</td>
<td></td>
<td><p></p></td>
</tr>
</tbody>
</table>

<h3 id="message-recognitionconfig">Message: RecognitionConfig</h3>

<p>Configuration for setting up a Recognizer</p>

<table>
<thead>
<tr>
<th>Field</th>
<th>Type</th>
<th>Label</th>
<th>Description</th>
</tr>
</thead>

<tbody>
<tr>
<td>model_id</td>
<td>string</td>
<td></td>
<td><p>Unique identifier of the model to use, as obtained from a <code>Model</code> message.</p></td>
</tr>

<tr>
<td>audio_encoding</td>
<td>RecognitionConfig.Encoding</td>
<td></td>
<td><p>Encoding of audio data sent/streamed through the <code>RecognitionAudio</code> messages. For encodings like WAV/MP3 that have headers, the headers are expected to be sent at the beginning of the stream, not in every <code>RecognitionAudio</code> message.</p><p>If not specified, the default encoding is RAW_LINEAR16.</p><p>Depending on how they are configured, server instances of this service may not support all the encodings enumerated above. They are always required to accept RAW_LINEAR16. If any other <code>Encoding</code> is specified, and it is not available on the server being used, the recognition request will result in an appropriate error message.</p></td>
</tr>

<tr>
<td>idle_timeout</td>
<td>google.protobuf.Duration</td>
<td></td>
<td><p>Idle Timeout of the created Recognizer. If no audio data is received by the recognizer for this duration, ongoing rpc calls will result in an error, the recognizer will be destroyed and thus more audio may not be sent to the same recognizer. The server may impose a limit on the maximum idle timeout that can be specified, and if the value in this message exceeds that serverside value, creating of the recognizer will fail with an error.</p></td>
</tr>

<tr>
<td>enable_word_time_offsets</td>
<td>bool</td>
<td></td>
<td><p>This is an optional field. If this is set to true, each result will include a list of words and the start time offset (timestamp) and the duration for each of those words. If set to <code>false</code>, no word-level timestamps will be returned. The default is <code>false</code>.</p></td>
</tr>

<tr>
<td>enable_word_confidence</td>
<td>bool</td>
<td></td>
<td><p>This is an optional field. If this is set to true, each result will include a list of words and the confidence for those words. If <code>false</code>, no word-level confidence information is returned. The default is <code>false</code>.</p></td>
</tr>

<tr>
<td>enable_raw_transcript</td>
<td>bool</td>
<td></td>
<td><p>This is an optional field. If this is set to true, the transcripts will be presented as raw output from the recognizer without any formatting rules applied. They will be in all UPPER CASE, numbers and other special entities would be presented as the spoken words. If set to <code>false</code>, formatting rules will be applied to all results. The default is <code>false</code>.</p><p>As an example, if the spoken utterance was <code>here are four words</code>: with this field set to <code>false</code>: &ldquo;Here are 4 words&rdquo; with this field set to &lsquo;true&rsquo; : &ldquo;HERE ARE FOUR WORDS&rdquo;</p></td>
</tr>

<tr>
<td>enable_confusion_network</td>
<td>bool</td>
<td></td>
<td><p>This is an optional field. If this is set to true, the results will include a confusion network. If set to <code>false</code>, no confusion network will be returned. The default is <code>false</code>. If the model being used does not support a confusion network, results may be returned without a confusion network available. If this field is set to <code>true</code>, then <code>enable_raw_transcript</code> is also forced to be true.</p></td>
</tr>

<tr>
<td>audio_channels</td>
<td>uint32</td>
<td>repeated</td>
<td><p>This is an optional field. If the audio has multiple channels, this field should be configured with the list of channel indices that should be transcribed. Channels are 0-indexed.</p><p>Example: <code>[0]</code> for a mono file, <code>[0, 1]</code> for a stereo file.</p><p>If this field is not set, a mono file will be assumed by default and only channel-0 will be transcribed even if the file actually has additional channels.</p><p>Channels that are present in the audio may be omitted, but it is an error to include a channel index in this field that is not present in the audio. Channels may be listed in any order but the same index may not be repeated in this list.</p><p>BAD: <code>[0, 2]</code> for a stereo file; BAD: <code>[0, 0]</code> for a mono file.</p></td>
</tr>
</tbody>
</table>

<h3 id="message-recognitionconfusionnetwork">Message: RecognitionConfusionNetwork</h3>

<p>Confusion network in recognition output</p>

<table>
<thead>
<tr>
<th>Field</th>
<th>Type</th>
<th>Label</th>
<th>Description</th>
</tr>
</thead>

<tbody>
<tr>
<td>links</td>
<td>ConfusionNetworkLink</td>
<td>repeated</td>
<td><p></p></td>
</tr>
</tbody>
</table>

<h3 id="message-recognitionresponse">Message: RecognitionResponse</h3>

<p>Collection of sequence of recognition results in a portion of audio.  When
transcribing a single audio channel (e.g. RAW_LINEAR16 input, or a mono
file), results will be ordered chronologically.  When transcribing multiple
channels, the results of all channels will be interleaved.  Results of each
individual channel will be chronological.  No such promise is made for the
ordering of results of different channels, as results are returned for each
channel individually as soon as they are ready.</p>

<table>
<thead>
<tr>
<th>Field</th>
<th>Type</th>
<th>Label</th>
<th>Description</th>
</tr>
</thead>

<tbody>
<tr>
<td>results</td>
<td>RecognitionResult</td>
<td>repeated</td>
<td><p></p></td>
</tr>
</tbody>
</table>

<h3 id="message-recognitionresult">Message: RecognitionResult</h3>

<p>A recognition result corresponding to a portion of audio.</p>

<table>
<thead>
<tr>
<th>Field</th>
<th>Type</th>
<th>Label</th>
<th>Description</th>
</tr>
</thead>

<tbody>
<tr>
<td>alternatives</td>
<td>RecognitionAlternative</td>
<td>repeated</td>
<td><p>An n-best list of recognition hypotheses alternatives</p></td>
</tr>

<tr>
<td>is_partial</td>
<td>bool</td>
<td></td>
<td><p>If this is set to true, it denotes that the result is an interim partial result, and could change after more audio is processed. If unset, or set to false, it denotes that this is a final result and will not change.</p><p>Servers are not required to implement support for returning partial results, and clients should generally not depend on their availability.</p></td>
</tr>

<tr>
<td>cnet</td>
<td>RecognitionConfusionNetwork</td>
<td></td>
<td><p>If <code>enable_confusion_network</code> was set to true in the <code>RecognitionConfig</code>, and if the model supports it, a confusion network will be available in the results.</p></td>
</tr>

<tr>
<td>audio_channel</td>
<td>uint32</td>
<td></td>
<td><p>Channel of the audio file that this result was transcribed from. For a mono file, or RAW_LINEAR16 input, this will be set to 0.</p></td>
</tr>
</tbody>
</table>

<h3 id="message-recognizerequest">Message: RecognizeRequest</h3>

<p>The top-level message sent by the client for the <code>Recognize</code> method.  Both
the <code>RecognitionConfig</code> and <code>RecognitionAudio</code> fields are required.  The
entire audio data must be sent in one request.  If your audio data is larger,
please use the <code>StreamingRecognize</code> call..</p>

<table>
<thead>
<tr>
<th>Field</th>
<th>Type</th>
<th>Label</th>
<th>Description</th>
</tr>
</thead>

<tbody>
<tr>
<td>config</td>
<td>RecognitionConfig</td>
<td></td>
<td><p>Provides configuration to create the recognizer.</p></td>
</tr>

<tr>
<td>audio</td>
<td>RecognitionAudio</td>
<td></td>
<td><p>The audio data to be recognized</p></td>
</tr>
</tbody>
</table>

<h3 id="message-streamingrecognizerequest">Message: StreamingRecognizeRequest</h3>

<p>The top-level message sent by the client for the <code>StreamingRecognize</code>
request.  Multiple <code>StreamingRecognizeRequest</code> messages are sent. The first
message must contain a <code>RecognitionConfig</code> message only, and all subsequent
messages must contain <code>RecognitionAudio</code> only.  All <code>RecognitionAudio</code>
messages must contain non-empty audio.  If audio content is empty, the server
may interpret it as end of stream and stop accepting any further messages.</p>

<table>
<thead>
<tr>
<th>Field</th>
<th>Type</th>
<th>Label</th>
<th>Description</th>
</tr>
</thead>

<tbody>
<tr>
<td>config</td>
<td>RecognitionConfig</td>
<td></td>
<td><p></p></td>
</tr>

<tr>
<td>audio</td>
<td>RecognitionAudio</td>
<td></td>
<td><p></p></td>
</tr>
</tbody>
</table>

<h3 id="message-versionresponse">Message: VersionResponse</h3>

<p>The message sent by the server for the <code>Version</code> method.</p>

<table>
<thead>
<tr>
<th>Field</th>
<th>Type</th>
<th>Label</th>
<th>Description</th>
</tr>
</thead>

<tbody>
<tr>
<td>cubic</td>
<td>string</td>
<td></td>
<td><p>version of the cubic library handling the recognition</p></td>
</tr>

<tr>
<td>server</td>
<td>string</td>
<td></td>
<td><p>version of the server handling these requests</p></td>
</tr>
</tbody>
</table>

<h3 id="message-wordinfo">Message: WordInfo</h3>

<p>Word-specific information for recognized words</p>

<table>
<thead>
<tr>
<th>Field</th>
<th>Type</th>
<th>Label</th>
<th>Description</th>
</tr>
</thead>

<tbody>
<tr>
<td>word</td>
<td>string</td>
<td></td>
<td><p>The actual word in the text</p></td>
</tr>

<tr>
<td>confidence</td>
<td>double</td>
<td></td>
<td><p>Confidence estimate between 0 and 1. A higher number represents a higher likelihood that the word was correctly recognized.</p></td>
</tr>

<tr>
<td>start_time</td>
<td>google.protobuf.Duration</td>
<td></td>
<td><p>Time offset relative to the beginning of audio received by the recognizer and corresponding to the start of this spoken word.</p></td>
</tr>

<tr>
<td>duration</td>
<td>google.protobuf.Duration</td>
<td></td>
<td><p>Duration of the current word in the spoken audio.</p></td>
</tr>
</tbody>
</table>

<p><!-- end messages --></p>

<h3 id="enum-recognitionconfig-encoding">Enum: RecognitionConfig.Encoding</h3>

<p>The encoding of the audio data to be sent for recognition.</p>

<p>For best results, the audio source should be captured and transmitted using
the RAW_LINEAR16 encoding.</p>

<table>
<thead>
<tr>
<th>Name</th>
<th>Number</th>
<th>Description</th>
</tr>
</thead>

<tbody>
<tr>
<td>RAW_LINEAR16</td>
<td>0</td>
<td>Raw (headerless) Uncompressed 16-bit signed little endian samples (linear PCM), single channel, sampled at the rate expected by the chosen <code>Model</code>.</td>
</tr>

<tr>
<td>WAV</td>
<td>1</td>
<td>WAV (data with RIFF headers), with data sampled at a rate equal to or higher than the sample rate expected by the chosen Model.</td>
</tr>

<tr>
<td>MP3</td>
<td>2</td>
<td>MP3 data, sampled at a rate equal to or higher than the sampling rate expected by the chosen Model.</td>
</tr>

<tr>
<td>FLAC</td>
<td>3</td>
<td>FLAC data, sampled at a rate equal to or higher than the sample rate expected by the chosen Model.</td>
</tr>

<tr>
<td>VOX8000</td>
<td>4</td>
<td>VOX data (Dialogic ADPCM), sampled at 8 KHz.</td>
</tr>

<tr>
<td>ULAW8000</td>
<td>5</td>
<td>μ-law (8-bit) encoded RAW data, single channel, sampled at 8 KHz.</td>
</tr>
</tbody>
</table>

<p><!-- end enums --></p>

<p><!-- end HasExtensions --></p>

<h2 id="scalar-value-types">Scalar Value Types</h2>

<table>
<thead>
<tr>
<th>.proto Type</th>
<th>Notes</th>
<th>Go Type</th>
<th>Python Type</th>
</tr>
</thead>

<tbody>
<tr>
<td>double</td>
<td></td>
<td>float64</td>
<td>float</td>
</tr>

<tr>
<td>float</td>
<td></td>
<td>float32</td>
<td>float</td>
</tr>

<tr>
<td>int32</td>
<td>Uses variable-length encoding. Inefficient for encoding negative numbers – if your field is likely to have negative values, use sint32 instead.</td>
<td>int32</td>
<td>int</td>
</tr>

<tr>
<td>int64</td>
<td>Uses variable-length encoding. Inefficient for encoding negative numbers – if your field is likely to have negative values, use sint64 instead.</td>
<td>int64</td>
<td>int/long</td>
</tr>

<tr>
<td>uint32</td>
<td>Uses variable-length encoding.</td>
<td>uint32</td>
<td>int/long</td>
</tr>

<tr>
<td>uint64</td>
<td>Uses variable-length encoding.</td>
<td>uint64</td>
<td>int/long</td>
</tr>

<tr>
<td>sint32</td>
<td>Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int32s.</td>
<td>int32</td>
<td>int</td>
</tr>

<tr>
<td>sint64</td>
<td>Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int64s.</td>
<td>int64</td>
<td>int/long</td>
</tr>

<tr>
<td>fixed32</td>
<td>Always four bytes. More efficient than uint32 if values are often greater than 2^28.</td>
<td>uint32</td>
<td>int</td>
</tr>

<tr>
<td>fixed64</td>
<td>Always eight bytes. More efficient than uint64 if values are often greater than 2^56.</td>
<td>uint64</td>
<td>int/long</td>
</tr>

<tr>
<td>sfixed32</td>
<td>Always four bytes.</td>
<td>int32</td>
<td>int</td>
</tr>

<tr>
<td>sfixed64</td>
<td>Always eight bytes.</td>
<td>int64</td>
<td>int/long</td>
</tr>

<tr>
<td>bool</td>
<td></td>
<td>bool</td>
<td>boolean</td>
</tr>

<tr>
<td>string</td>
<td>A string must always contain UTF-8 encoded or 7-bit ASCII text.</td>
<td>string</td>
<td>str/unicode</td>
</tr>

<tr>
<td>bytes</td>
<td>May contain any arbitrary sequence of bytes.</td>
<td>[]byte</td>
<td>str</td>
</tr>
</tbody>
</table>


    
    
          <footer class=" footline" >
	
</footer>
  </div>
</div>

<div id="navigation">
<a class="nav nav-prev" href="/sdk-cubic/protobuf/" title="Protobuf Reference"> <i class="fa fa-chevron-left"></i><label>Protobuf Reference</label></a>
    <a class="nav nav-next" href="/sdk-cubic/getting-started/" title="Getting started" style="margin-right: 0px;"><label>Getting started</label><i class="fa fa-chevron-right"></i></a></div>

</section>
<div style="left: -1000px; overflow: scroll; position: absolute; top: -1000px; border: none; box-sizing: content-box; height: 200px; margin: 0px; padding: 0px; width: 200px;">
  <div style="border: none; box-sizing: content-box; height: 200px; margin: 0px; padding: 0px; width: 200px;"></div>
</div>    

<script src="/sdk-cubic/js/clipboard.min.js"></script>
<script src="/sdk-cubic/js/featherlight.min.js"></script>
<script src="/sdk-cubic/js/html5shiv-printshiv.min.js"></script>

<script src="/sdk-cubic/js/modernizr.custom.71422.js"></script>
<script src="/sdk-cubic/js/docdock.js"></script>
<script src="/sdk-cubic/theme-original/script.js"></script>


    

    
    

    
  </body>
</html>